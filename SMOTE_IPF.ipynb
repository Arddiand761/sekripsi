{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C8S3UZT41dIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5431a413-0fa3-40bb-fe86-273f24548c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vxTMRP5128hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16801349-5f7c-4a21-deb0-0a02aae6e005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Path root: gdrive/My Drive/Colab Notebooks/Deep Learning Labs/Framingham/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/Deep Learning Labs/Framingham/'\n",
        "\n",
        "print(\"Path root:\", root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VyMJ5CfS05Ot"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Imports rekomendasi untuk eksperimen SMOTE / SMOTE-IPF / CV / tuning\n",
        "# -------------------------\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Reproducibility: gunakan nilai tunggal untuk random_state sepanjang notebook\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# sklearn: preprocessing, model, evaluasi, CV, dan util lainnya\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, auc\n",
        "\n",
        "# imbalanced-learn: pipeline + samplers (SMOTE + variants)\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline   # alias supaya tidak bingung dengan sklearn.pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "\n",
        "# plotting (opsional tapi berguna untuk presentasi)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# untuk implementasi custom SMOTE-IPF, pastikan class/func SMOTE_IPF sudah didefinisikan/imported\n",
        "# from your_module import SMOTE_IPF   # contoh jika kamu punya file implementasi SMOTE_IPF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XBvDrHGY1Yeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a965aaba-40c6-4689-941d-5269c5483be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ukuran dataset: (4240, 16)\n",
            "\n",
            "Jumlah missing value per kolom:\n",
            " male                 0\n",
            "age                  0\n",
            "education          105\n",
            "currentSmoker        0\n",
            "cigsPerDay          29\n",
            "BPMeds              53\n",
            "prevalentStroke      0\n",
            "prevalentHyp         0\n",
            "diabetes             0\n",
            "totChol             50\n",
            "sysBP                0\n",
            "diaBP                0\n",
            "BMI                 19\n",
            "heartRate            1\n",
            "glucose            388\n",
            "TenYearCHD           0\n",
            "dtype: int64\n",
            "\n",
            "Info dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4240 entries, 0 to 4239\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   male             4240 non-null   int64  \n",
            " 1   age              4240 non-null   int64  \n",
            " 2   education        4135 non-null   float64\n",
            " 3   currentSmoker    4240 non-null   int64  \n",
            " 4   cigsPerDay       4211 non-null   float64\n",
            " 5   BPMeds           4187 non-null   float64\n",
            " 6   prevalentStroke  4240 non-null   int64  \n",
            " 7   prevalentHyp     4240 non-null   int64  \n",
            " 8   diabetes         4240 non-null   int64  \n",
            " 9   totChol          4190 non-null   float64\n",
            " 10  sysBP            4240 non-null   float64\n",
            " 11  diaBP            4240 non-null   float64\n",
            " 12  BMI              4221 non-null   float64\n",
            " 13  heartRate        4239 non-null   float64\n",
            " 14  glucose          3852 non-null   float64\n",
            " 15  TenYearCHD       4240 non-null   int64  \n",
            "dtypes: float64(9), int64(7)\n",
            "memory usage: 530.1 KB\n",
            "None\n",
            "\n",
            "Distribusi label target (TenYearCHD):\n",
            "TenYearCHD\n",
            "0    0.848113\n",
            "1    0.151887\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Load dataset\n",
        "# -------------------------\n",
        "df = pd.read_csv(os.path.join(root_path, \"framingham.csv\"))\n",
        "\n",
        "# Info dasar dataset\n",
        "print(\"Ukuran dataset:\", df.shape)\n",
        "print(\"\\nJumlah missing value per kolom:\\n\", df.isnull().sum())\n",
        "\n",
        "# Cek tipe data\n",
        "print(\"\\nInfo dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# (Opsional) lihat distribusi target\n",
        "if \"TenYearCHD\" in df.columns:\n",
        "    print(\"\\nDistribusi label target (TenYearCHD):\")\n",
        "    print(df[\"TenYearCHD\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AWcDgvJQ3nAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ed9558-e0bc-40a8-d9e0-7c4490a87735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah missing value setelah imputasi:\n",
            " 0\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Tangani missing values\n",
        "# -------------------------\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Pisahkan kolom numerik dan kategorikal\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Imputer untuk numerik (pakai median biar robust ke outlier)\n",
        "imputer_num = SimpleImputer(strategy=\"median\")\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Imputer untuk kategorikal (kalau ada, pakai modus)\n",
        "if len(cat_cols) > 0:\n",
        "    imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "print(\"Jumlah missing value setelah imputasi:\\n\", df.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "msQHiO5G3ru3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710532dd-d922-42d2-faca-4c5103e2a5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi kelas di train: [2517  451]\n",
            "Distribusi kelas di test : [1079  193]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(\"TenYearCHD\", axis=1)\n",
        "y = df[\"TenYearCHD\"]\n",
        "\n",
        "# Stratify untuk menjaga proporsi kelas tetap sama di train & test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, shuffle=True, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Distribusi kelas di train:\", np.bincount(y_train))\n",
        "print(\"Distribusi kelas di test :\", np.bincount(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RYEMjJQm3tWp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalisasi fitur agar semua punya skala yang sebanding\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # scaler \"belajar\" dari train\n",
        "X_test_scaled = scaler.transform(X_test)        # hanya transform, tidak fit ulang\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Jumlah sampel sebelum SMOTE-IPF:\", X_train.shape)\n",
        "print(\"Distribusi kelas sebelum SMOTE-IPF:\", np.bincount(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_x3Hkdnkqip",
        "outputId": "3b6ef23e-bedb-456e-8615-e13515dc5abd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah sampel sebelum SMOTE-IPF: (2968, 15)\n",
            "Distribusi kelas sebelum SMOTE-IPF: [2517  451]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VGD9r2283vIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b62ca0-6ee1-47ab-c9a4-37ebc35ffd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Baseline SVM (Tanpa SMOTE-IPF) ===\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      1.00      0.92      1079\n",
            "         1.0       0.62      0.03      0.05       193\n",
            "\n",
            "    accuracy                           0.85      1272\n",
            "   macro avg       0.74      0.51      0.48      1272\n",
            "weighted avg       0.82      0.85      0.79      1272\n",
            "\n",
            "F1-Score: 0.04975124378109453\n",
            "Confusion Matrix:\n",
            " [[1076    3]\n",
            " [ 188    5]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# Baseline SVM (tanpa SMOTE/IPF)\n",
        "svm = SVC(random_state=42)  # random_state biar konsisten\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred = svm.predict(X_test_scaled)\n",
        "\n",
        "print(\"=== Baseline SVM (Tanpa SMOTE-IPF) ===\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dZ2vQkMv3w2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66530182-2359-4f4a-c1da-84be55523f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rata-rata F1-Score CV (Tanpa SMOTE-IPF): 0.03892389763269924\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "pipeline_svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"svm\", SVC())\n",
        "])\n",
        "\n",
        "scores = cross_val_score(pipeline_svm, X, y, cv=cv, scoring=\"f1\")\n",
        "print(\"Rata-rata F1-Score CV (Tanpa SMOTE-IPF):\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# --- Oversampling dengan SMOTE ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Jumlah setelah SMOTE:\", X_resampled.shape)\n",
        "print(\"Distribusi kelas setelah SMOTE:\", np.bincount(y_resampled))\n",
        "\n",
        "# --- Training SVM dengan data hasil SMOTE ---\n",
        "svm_smote = SVC(kernel='linear', C=10, gamma=0.1, class_weight='balanced', random_state=42)\n",
        "svm_smote.fit(X_resampled, y_resampled)\n",
        "y_pred_smote = svm_smote.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n=== SVM + SMOTE (Tuned) ===\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_smote))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred_smote))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_smote))\n",
        "\n",
        "# --- Cross-validation dengan pipeline ---\n",
        "pipeline_smote_svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"svm\", SVC(random_state=42))\n",
        "])\n",
        "\n",
        "scores_smote = cross_val_score(pipeline_smote_svm, X, y, cv=cv, scoring=\"f1\")\n",
        "print(\"\\nRata-rata F1-Score CV (SVM + SMOTE):\", scores_smote.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMPG_uplbecb",
        "outputId": "ee2c8c5c-380f-4ee0-e6a7-5fa8b8cd2ee6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah setelah SMOTE: (5034, 15)\n",
            "Distribusi kelas setelah SMOTE: [2517 2517]\n",
            "\n",
            "=== SVM + SMOTE (Tuned) ===\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.64      0.75      1079\n",
            "         1.0       0.24      0.62      0.34       193\n",
            "\n",
            "    accuracy                           0.64      1272\n",
            "   macro avg       0.57      0.63      0.55      1272\n",
            "weighted avg       0.80      0.64      0.69      1272\n",
            "\n",
            "F1-Score: 0.3438395415472779\n",
            "Confusion Matrix:\n",
            " [[694 385]\n",
            " [ 73 120]]\n",
            "\n",
            "Rata-rata F1-Score CV (SVM + SMOTE): 0.32868597964721846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gV_65FOy3zWa"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "class SMOTE_IPF:\n",
        "    def __init__(self, smote_k=15, ipf_k=10, max_iter=5, random_state=42, verbose=False):\n",
        "        self.smote_k = smote_k\n",
        "        self.ipf_k = ipf_k\n",
        "        self.max_iter = max_iter\n",
        "        self.verbose = verbose\n",
        "        self.smote = SMOTE(k_neighbors=self.smote_k, random_state=random_state)\n",
        "\n",
        "    def fit_resample(self, X, y):\n",
        "        # Step 1: SMOTE\n",
        "        X_resampled, y_resampled = self.smote.fit_resample(X, y)\n",
        "\n",
        "        # Gabungkan X dan y\n",
        "        y_array = np.array(y_resampled).reshape(-1, 1)\n",
        "        data = np.hstack((X_resampled.copy(), y_array))\n",
        "\n",
        "        # Step 2: Iterative Partitioning Filter (IPF)\n",
        "        for i in range(self.max_iter):\n",
        "            clf = KNeighborsClassifier(n_neighbors=self.ipf_k)\n",
        "            X_curr = data[:, :-1]\n",
        "            y_curr = data[:, -1]\n",
        "\n",
        "            clf.fit(X_curr, y_curr)\n",
        "            y_pred = clf.predict(X_curr)\n",
        "\n",
        "            # Temukan sample yang salah klasifikasi\n",
        "            misclassified = y_pred != y_curr\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"Iterasi {i+1}: {misclassified.sum()} data dibuang\")\n",
        "\n",
        "            # Jika tidak ada yang misclassified â†’ stop\n",
        "            if not np.any(misclassified):\n",
        "                break\n",
        "\n",
        "            # Hapus sample yang salah klasifikasi\n",
        "            data = data[~misclassified]\n",
        "\n",
        "        return data[:, :-1], data[:, -1].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qtxtKO0M36tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5059bbca-6ec0-40ba-8765-5d9efef5faa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterasi 1: 451 data dibuang\n",
            "Iterasi 2: 93 data dibuang\n",
            "Iterasi 3: 12 data dibuang\n",
            "Iterasi 4: 1 data dibuang\n",
            "Iterasi 5: 0 data dibuang\n",
            "Jumlah setelah SMOTE-IPF: (4477, 15)\n",
            "Distribusi kelas setelah SMOTE-IPF: [1966 2511]\n"
          ]
        }
      ],
      "source": [
        "# --- Oversampling dengan SMOTE-IPF ---\n",
        "smote_ipf = SMOTE_IPF(smote_k=5, ipf_k=3, max_iter=5, random_state=42, verbose=True)\n",
        "X_resampled_ipf, y_resampled_ipf = smote_ipf.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Jumlah setelah SMOTE-IPF:\", X_resampled_ipf.shape)\n",
        "print(\"Distribusi kelas setelah SMOTE-IPF:\", np.bincount(y_resampled_ipf))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Jumlah sesudah SMOTE-IPF:\", X_resampled_ipf.shape, np.bincount(y_resampled_ipf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOMFBwf6kyJt",
        "outputId": "b7e725ce-0ded-46e7-ef91-68cda0158c62"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah sesudah SMOTE-IPF: (4477, 15) [1966 2511]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "o1ONMCIM4Aqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30622249-15c1-450c-b0fa-58b1806c3aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SVM + SMOTE-IPF (Test set) ===\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.63      0.75      1079\n",
            "         1.0       0.24      0.64      0.35       193\n",
            "\n",
            "    accuracy                           0.64      1272\n",
            "   macro avg       0.57      0.64      0.55      1272\n",
            "weighted avg       0.81      0.64      0.69      1272\n",
            "\n",
            "F1-Score (pos=1): 0.34831460674157305\n",
            "Confusion Matrix:\n",
            " [[684 395]\n",
            " [ 69 124]]\n"
          ]
        }
      ],
      "source": [
        "# Asumsikan X_resampled_ipf, y_resampled_ipf sudah dibuat\n",
        "# Jika belum, ganti X_resampled_ipf/y_resampled_ipf dengan X_resampled/y_resampled (tapi usahakan beri nama ipf)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# 1) Train SVM pada data hasil SMOTE-IPF\n",
        "svm_resampled = SVC(kernel='linear', C=10, gamma=0.1, class_weight='balanced', random_state=42)   # tambahkan random_state\n",
        "svm_resampled.fit(X_resampled_ipf, y_resampled_ipf)\n",
        "\n",
        "# 2) Prediksi di test set (gunakan X_test_scaled yang sudah kamu buat)\n",
        "y_pred_resampled = svm_resampled.predict(X_test_scaled)\n",
        "\n",
        "# 3) Evaluasi lengkap\n",
        "print(\"=== SVM + SMOTE-IPF (Test set) ===\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_resampled))\n",
        "print(\"F1-Score (pos=1):\", f1_score(y_test, y_pred_resampled, pos_label=1))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_resampled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhKQFEMJ38nW"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Stratified CV dengan shuffle biar merata\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Pipeline: scaler -> SMOTE-IPF -> SVM\n",
        "pipeline_resampled = make_pipeline_imb(\n",
        "    StandardScaler(),\n",
        "    SMOTE_IPF(smote_k=5, ipf_k=3, max_iter=5),  # param bisa kamu tune\n",
        "    SVC(random_state=42)\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "scores_resampled = cross_val_score(pipeline_resampled, X, y, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "\n",
        "print(\"Rata-rata F1-Score CV (SMOTE-IPF + SVM):\", scores_resampled.mean())\n",
        "print(\"Std dev F1-Score CV:\", scores_resampled.std())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}