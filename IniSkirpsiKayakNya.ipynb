{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7265,
     "status": "ok",
     "timestamp": 1759364299410,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "6iAOOx4N5pTE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, auc\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1759364299443,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "mWMqigZX5w05",
    "outputId": "9e688bdc-91c3-42e6-9c5b-b28a1473ec9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset: (4240, 16)\n",
      "\n",
      "Jumlah missing value per kolom:\n",
      " male                 0\n",
      "age                  0\n",
      "education          105\n",
      "currentSmoker        0\n",
      "cigsPerDay          29\n",
      "BPMeds              53\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             50\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 19\n",
      "heartRate            1\n",
      "glucose            388\n",
      "TenYearCHD           0\n",
      "dtype: int64\n",
      "\n",
      "Info dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4240 entries, 0 to 4239\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4240 non-null   int64  \n",
      " 1   age              4240 non-null   int64  \n",
      " 2   education        4135 non-null   float64\n",
      " 3   currentSmoker    4240 non-null   int64  \n",
      " 4   cigsPerDay       4211 non-null   float64\n",
      " 5   BPMeds           4187 non-null   float64\n",
      " 6   prevalentStroke  4240 non-null   int64  \n",
      " 7   prevalentHyp     4240 non-null   int64  \n",
      " 8   diabetes         4240 non-null   int64  \n",
      " 9   totChol          4190 non-null   float64\n",
      " 10  sysBP            4240 non-null   float64\n",
      " 11  diaBP            4240 non-null   float64\n",
      " 12  BMI              4221 non-null   float64\n",
      " 13  heartRate        4239 non-null   float64\n",
      " 14  glucose          3852 non-null   float64\n",
      " 15  TenYearCHD       4240 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 530.1 KB\n",
      "None\n",
      "\n",
      "Distribusi label target (TenYearCHD):\n",
      "TenYearCHD\n",
      "0    0.848113\n",
      "1    0.151887\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"framingham.csv\")\n",
    "\n",
    "\n",
    "print(\"Ukuran dataset:\", df.shape)\n",
    "print(\"\\nJumlah missing value per kolom:\\n\", df.isnull().sum())\n",
    "\n",
    "\n",
    "print(\"\\nInfo dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "if \"TenYearCHD\" in df.columns:\n",
    "    print(\"\\nDistribusi label target (TenYearCHD):\")\n",
    "    print(df[\"TenYearCHD\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male   age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0   1.0  39.0        4.0            0.0         0.0     0.0              0.0   \n",
       "1   0.0  46.0        2.0            0.0         0.0     0.0              0.0   \n",
       "2   1.0  48.0        1.0            1.0        20.0     0.0              0.0   \n",
       "3   0.0  61.0        3.0            1.0        30.0     0.0              0.0   \n",
       "4   0.0  46.0        3.0            1.0        23.0     0.0              0.0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0           0.0       0.0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1           0.0       0.0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2           0.0       0.0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3           1.0       0.0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4           0.0       0.0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         1.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1759364299492,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "RwP6fWev6D7T",
    "outputId": "18eb34ef-ebc5-4f26-e70e-d1c8d0567cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value setelah imputasi:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "imputer_num = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "\n",
    "print(\"Jumlah missing value setelah imputasi:\\n\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1759364504729,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "6X3QOyuP5x6_",
    "outputId": "db7106ce-a202-4d8e-ad79-8c98fa73780e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALISIS FITUR DATASET FRAMINGHAM ===\n",
      "Total fitur tersedia: 15\n",
      "Fitur yang tersedia: ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
      "\n",
      "=== TOP FITUR BERDASARKAN KORELASI ===\n",
      "Top 8 fitur berdasarkan korelasi:\n",
      " 1. age            : 0.225\n",
      " 2. sysBP          : 0.216\n",
      " 3. prevalentHyp   : 0.177\n",
      " 4. diaBP          : 0.145\n",
      " 5. glucose        : 0.121\n",
      " 6. diabetes       : 0.097\n",
      " 7. male           : 0.088\n",
      " 8. BPMeds         : 0.086\n",
      "\n",
      "=== VALIDASI KOMBINASI FITUR ===\n",
      "âœ… Combo_1_Basic: ['age', 'male', 'currentSmoker', 'totChol']\n",
      "âœ… Combo_2_BP: ['age', 'male', 'sysBP', 'diaBP']\n",
      "âœ… Combo_3_Risk: ['age', 'totChol', 'sysBP', 'diabetes']\n",
      "âœ… Combo_4_Lifestyle: ['age', 'male', 'currentSmoker', 'BMI']\n",
      "âœ… Combo_5_Top_Corr: ['age', 'sysBP', 'prevalentHyp', 'diaBP']\n",
      "\n",
      "ðŸŽ¯ FITUR TERPILIH: Combo_5_Top_Corr\n",
      "Fitur yang digunakan: ['age', 'sysBP', 'prevalentHyp', 'diaBP']\n",
      "Jumlah fitur: 4 dari 15 total\n",
      "\n",
      "=== HASIL SPLIT DATA ===\n",
      "Shape X_train: (2968, 4)\n",
      "Shape X_test: (1272, 4)\n",
      "Distribusi kelas di train: [2517  451]\n",
      "Distribusi kelas di test : [1079  193]\n",
      "\n",
      "=== STATISTIK FITUR TERPILIH ===\n",
      "age:\n",
      "  No CHD: mean=48.85\n",
      "  CHD:    mean=54.67\n",
      "  Correlation: 0.225\n",
      "\n",
      "sysBP:\n",
      "  No CHD: mean=130.27\n",
      "  CHD:    mean=144.00\n",
      "  Correlation: 0.216\n",
      "\n",
      "prevalentHyp:\n",
      "  No CHD: mean=0.27\n",
      "  CHD:    mean=0.51\n",
      "  Correlation: 0.177\n",
      "\n",
      "diaBP:\n",
      "  No CHD: mean=82.08\n",
      "  CHD:    mean=87.17\n",
      "  Correlation: 0.145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION & TRAIN-TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === ANALISIS FITUR UNTUK FEATURE SELECTION ===\n",
    "print(\"=== ANALISIS FITUR DATASET FRAMINGHAM ===\")\n",
    "feature_columns = [col for col in df.columns if col != 'TenYearCHD']\n",
    "print(f\"Total fitur tersedia: {len(feature_columns)}\")\n",
    "print(\"Fitur yang tersedia:\", feature_columns)\n",
    "\n",
    "# Analisis korelasi dengan target\n",
    "print(f\"\\n=== TOP FITUR BERDASARKAN KORELASI ===\")\n",
    "correlations = df.corr()['TenYearCHD'].drop('TenYearCHD').abs().sort_values(ascending=False)\n",
    "print(\"Top 8 fitur berdasarkan korelasi:\")\n",
    "for i, (feature, corr) in enumerate(correlations.head(8).items(), 1):\n",
    "    print(f\"{i:2d}. {feature:15s}: {corr:.3f}\")\n",
    "\n",
    "# === DEFINISI KOMBINASI 4 FITUR ===\n",
    "# Berdasarkan domain knowledge CHD dan korelasi\n",
    "feature_combinations = {\n",
    "    'Combo_1_Basic': ['age', 'male', 'currentSmoker', 'totChol'],\n",
    "    'Combo_2_BP': ['age', 'male', 'sysBP', 'diaBP'], \n",
    "    'Combo_3_Risk': ['age', 'totChol', 'sysBP', 'diabetes'],\n",
    "    'Combo_4_Lifestyle': ['age', 'male', 'currentSmoker', 'BMI'],\n",
    "    'Combo_5_Top_Corr': list(correlations.head(4).index)  # 4 fitur korelasi tertinggi\n",
    "}\n",
    "\n",
    "# Pastikan fitur ada dan valid\n",
    "print(f\"\\n=== VALIDASI KOMBINASI FITUR ===\")\n",
    "valid_combinations = {}\n",
    "for combo_name, features in feature_combinations.items():\n",
    "    missing = [f for f in features if f not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"âŒ {combo_name}: Missing {missing}\")\n",
    "        # Ganti dengan fitur alternatif\n",
    "        available = [f for f in features if f in df.columns]\n",
    "        remaining = [f for f in feature_columns if f not in available][:4-len(available)]\n",
    "        features = (available + remaining)[:4]\n",
    "    \n",
    "    valid_combinations[combo_name] = features\n",
    "    print(f\"âœ… {combo_name}: {features}\")\n",
    "\n",
    "# === PILIH KOMBINASI TERBAIK (ATAU USER BISA GANTI) ===\n",
    "# Gunakan kombinasi dengan korelasi tertinggi sebagai default\n",
    "selected_combo = 'Combo_5_Top_Corr'\n",
    "selected_features = valid_combinations[selected_combo]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FITUR TERPILIH: {selected_combo}\")\n",
    "print(f\"Fitur yang digunakan: {selected_features}\")\n",
    "print(f\"Jumlah fitur: {len(selected_features)} dari {len(feature_columns)} total\")\n",
    "\n",
    "# === SPLIT DATA DENGAN FITUR TERPILIH ===\n",
    "X = df[selected_features]  # Hanya gunakan fitur terpilih\n",
    "y = df[\"TenYearCHD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=True, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n=== HASIL SPLIT DATA ===\")\n",
    "print(\"Shape X_train:\", X_train.shape)\n",
    "print(\"Shape X_test:\", X_test.shape)\n",
    "print(\"Distribusi kelas di train:\", np.bincount(y_train))\n",
    "print(\"Distribusi kelas di test :\", np.bincount(y_test))\n",
    "\n",
    "# Tampilkan statistik fitur terpilih\n",
    "print(f\"\\n=== STATISTIK FITUR TERPILIH ===\")\n",
    "for feature in selected_features:\n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  No CHD: mean={X_train[X_train.index.isin(y_train[y_train==0].index)][feature].mean():.2f}\")\n",
    "    print(f\"  CHD:    mean={X_train[X_train.index.isin(y_train[y_train==1].index)][feature].mean():.2f}\")\n",
    "    print(f\"  Correlation: {correlations[feature]:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759364506159,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "HV4DcOtz53Gm",
    "outputId": "b8e3e8c3-b793-4823-db7b-da47a993edeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi y_train: Counter({0.0: 2517, 1.0: 451})\n",
      "Distribusi y_test: Counter({0.0: 1079, 1.0: 193})\n",
      "\n",
      "Baseline (most_frequent) Accuracy: 0.8482704402515723\n",
      "Baseline (most_frequent) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.848     1.000     0.918      1079\n",
      "         1.0      0.000     0.000     0.000       193\n",
      "\n",
      "    accuracy                          0.848      1272\n",
      "   macro avg      0.424     0.500     0.459      1272\n",
      "weighted avg      0.720     0.848     0.779      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell A: cek distribusi label dan baseline majority\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Distribusi y_train:\", Counter(y_train))\n",
    "print(\"Distribusi y_test:\", Counter(y_test))\n",
    "\n",
    "# Baseline majority\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy = dummy.predict(X_test)\n",
    "print(\"\\nBaseline (most_frequent) Accuracy:\", accuracy_score(y_test, y_dummy))\n",
    "print(\"Baseline (most_frequent) Classification Report:\\n\", classification_report(y_test, y_dummy, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1759364508588,
     "user": {
      "displayName": "Arddian",
      "userId": "16616596264076823747"
     },
     "user_tz": -420
    },
    "id": "P6cClY2056Kr",
    "outputId": "9b796e74-3871-4055-8e09-774f09f76f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2968, 4) -> (2968, 4)\n",
      "(1272, 4) -> (1272, 4)\n"
     ]
    }
   ],
   "source": [
    "# Cell B: scaler yang benar (StandardScaler contoh)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # FIT hanya di train\n",
    "X_test_scaled  = scaler.transform(X_test)        # TRANSFORM di test\n",
    "\n",
    "# Cek shape\n",
    "print(X_train.shape, '->', X_train_scaled.shape)\n",
    "print(X_test.shape, '->', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bn57X9O657Tu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (no class_weight) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.848     1.000     0.918      1079\n",
      "         1.0      0.000     0.000     0.000       193\n",
      "\n",
      "    accuracy                          0.848      1272\n",
      "   macro avg      0.424     0.500     0.459      1272\n",
      "weighted avg      0.720     0.848     0.779      1272\n",
      "\n",
      "Accuracy: 0.8482704402515723\n",
      "F1-score (pos=1): 0.0\n",
      "Confusion Matrix:\n",
      " [[1079    0]\n",
      " [ 193    0]]\n"
     ]
    }
   ],
   "source": [
    "# Cell C: SVM tanpa class_weight (mungkin mirip dengan baseline dosen)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_plain = SVC(kernel='linear', C=1.0, probability=True, random_state=42)  # gamma dihapus karena linear\n",
    "svm_plain.fit(X_train_scaled, y_train)\n",
    "y_pred_plain = svm_plain.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM (no class_weight) Classification Report:\\n\", classification_report(y_test, y_pred_plain, digits=3))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_plain))\n",
    "print(\"F1-score (pos=1):\", f1_score(y_test, y_pred_plain, pos_label=1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_plain))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jyoYLa7058Ul"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah setelah SMOTE: (3775, 4) [2517 1258]\n",
      "\n",
      "=== HASIL SVM + SMOTE ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.864     0.942     0.901      1079\n",
      "         1.0      0.344     0.171     0.228       193\n",
      "\n",
      "    accuracy                          0.825      1272\n",
      "   macro avg      0.604     0.556     0.565      1272\n",
      "weighted avg      0.785     0.825     0.799      1272\n",
      "\n",
      "F1-Score: 0.22837370242214533\n",
      "\n",
      "=== PERBANDINGAN ===\n",
      "F1-Score Baseline SVM: 0.0\n",
      "F1-Score SVM + SMOTE: 0.22837370242214533\n",
      "Improvement: 0.22837370242214533\n"
     ]
    }
   ],
   "source": [
    "# SMOTE + SVM\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Terapkan SMOTE pada data training\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42, k_neighbors=3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Jumlah setelah SMOTE:\", X_resampled.shape, np.bincount(y_resampled))\n",
    "\n",
    "# SVM dengan parameter yang lebih optimal\n",
    "svm_smote = SVC(kernel='linear', C=0.5, random_state=42)  # Lebih simpel dan cepat\n",
    "svm_smote.fit(X_resampled, y_resampled)\n",
    "y_pred_smote = svm_smote.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== HASIL SVM + SMOTE ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_smote, digits=3))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_smote))\n",
    "\n",
    "# Bandingkan dengan baseline SVM\n",
    "print(\"\\n=== PERBANDINGAN ===\")\n",
    "print(\"F1-Score Baseline SVM:\", f1_score(y_test, y_pred_plain))\n",
    "print(\"F1-Score SVM + SMOTE:\", f1_score(y_test, y_pred_smote))\n",
    "print(\"Improvement:\", f1_score(y_test, y_pred_smote) - f1_score(y_test, y_pred_plain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "class SMOTE_IPF(BaseEstimator):\n",
    "    \"\"\"\n",
    "    SMOTE-IPF: SMOTE dengan Iterative Partitioning Filter\n",
    "    Optimized version untuk skripsi\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smote_k=5, ipf_k=5, max_iter=10, sampling_strategy=0.5,\n",
    "                 random_state=None, verbose=False, remove_only_synthetic=True):\n",
    "        # Parameter validation\n",
    "        if smote_k < 1 or ipf_k < 1:\n",
    "            raise ValueError(\"k values must be >= 1\")\n",
    "        if max_iter < 1:\n",
    "            raise ValueError(\"max_iter must be >= 1\")\n",
    "            \n",
    "        self.smote_k = smote_k\n",
    "        self.ipf_k = min(ipf_k, smote_k)  # IPF k tidak boleh > SMOTE k\n",
    "        self.max_iter = max_iter\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.remove_only_synthetic = remove_only_synthetic\n",
    "        \n",
    "    def fit_resample(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit dan resample data menggunakan SMOTE-IPF\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        y = np.asarray(y).astype(int).ravel()\n",
    "        \n",
    "        if len(np.unique(y)) < 2:\n",
    "            raise ValueError(\"Need at least 2 classes\")\n",
    "            \n",
    "        n_orig = X.shape[0]\n",
    "        \n",
    "        # Step 1: Apply SMOTE\n",
    "        smote = SMOTE(\n",
    "            k_neighbors=self.smote_k,\n",
    "            sampling_strategy=self.sampling_strategy,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        X_res, y_res = smote.fit_resample(X, y)\n",
    "        \n",
    "        # Step 2: Track synthetic samples\n",
    "        n_after_smote = X_res.shape[0]\n",
    "        n_synthetic = n_after_smote - n_orig\n",
    "        \n",
    "        # Boolean mask untuk synthetic samples\n",
    "        is_synthetic = np.zeros(n_after_smote, dtype=bool)\n",
    "        if n_synthetic > 0:\n",
    "            is_synthetic[n_orig:] = True\n",
    "            \n",
    "        if self.verbose:\n",
    "            unique, counts = np.unique(y_res, return_counts=True)\n",
    "            print(f\"[SMOTE] Total: {n_after_smote}, Synthetic: {n_synthetic}\")\n",
    "            print(f\"[SMOTE] Class distribution: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        # Step 3: Iterative Partitioning Filter\n",
    "        X_current = X_res.copy()\n",
    "        y_current = y_res.copy()\n",
    "        synthetic_current = is_synthetic.copy()\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            if len(X_current) == 0:\n",
    "                break\n",
    "                \n",
    "            # Train KNN classifier\n",
    "            n_neighbors = min(self.ipf_k, len(X_current) - 1)\n",
    "            if n_neighbors < 1:\n",
    "                break\n",
    "                \n",
    "            clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            clf.fit(X_current, y_current)\n",
    "            y_pred = clf.predict(X_current)\n",
    "            \n",
    "            # Find misclassified samples\n",
    "            misclassified = (y_pred != y_current)\n",
    "            n_misclassified = misclassified.sum()\n",
    "            \n",
    "            if n_misclassified == 0:\n",
    "                if self.verbose:\n",
    "                    print(f\"[IPF] Iter {iteration+1}: No misclassified -> STOP\")\n",
    "                break\n",
    "            \n",
    "            # Determine which samples to remove\n",
    "            if self.remove_only_synthetic:\n",
    "                # Only remove synthetic misclassified samples\n",
    "                to_remove = misclassified & synthetic_current\n",
    "                n_removed = to_remove.sum()\n",
    "                \n",
    "                if n_removed == 0:\n",
    "                    if self.verbose:\n",
    "                        print(f\"[IPF] Iter {iteration+1}: Only original misclassified -> STOP\")\n",
    "                    break\n",
    "            else:\n",
    "                # Remove all misclassified samples\n",
    "                to_remove = misclassified\n",
    "                n_removed = to_remove.sum()\n",
    "            \n",
    "            # Update arrays\n",
    "            keep_mask = ~to_remove\n",
    "            X_current = X_current[keep_mask]\n",
    "            y_current = y_current[keep_mask]\n",
    "            synthetic_current = synthetic_current[keep_mask]\n",
    "            \n",
    "            if self.verbose:\n",
    "                unique, counts = np.unique(y_current, return_counts=True)\n",
    "                print(f\"[IPF] Iter {iteration+1}: Removed {n_removed}/{n_misclassified}, \"\n",
    "                      f\"Remaining: {len(X_current)}, \"\n",
    "                      f\"Distribution: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            unique, counts = np.unique(y_current, return_counts=True)\n",
    "            synthetic_remaining = synthetic_current.sum()\n",
    "            print(f\"[FINAL] Total: {len(X_current)}, Synthetic remaining: {synthetic_remaining}\")\n",
    "            print(f\"[FINAL] Class distribution: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        return X_current, y_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING SMOTE-IPF ===\n",
      "[SMOTE] Total: 3775, Synthetic: 807\n",
      "[SMOTE] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(1258)}\n",
      "[IPF] Iter 1: Removed 60/415, Remaining: 3715, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(1198)}\n",
      "[IPF] Iter 2: Removed 7/352, Remaining: 3708, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(1191)}\n",
      "[IPF] Iter 3: Only original misclassified -> STOP\n",
      "[FINAL] Total: 3708, Synthetic remaining: 740\n",
      "[FINAL] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(1191)}\n",
      "\n",
      "Distribusi akhir SMOTE-IPF: [2517 1191]\n",
      "\n",
      "=== HASIL SVM + SMOTE-IPF ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.960     0.907      1079\n",
      "         1.0      0.358     0.124     0.185       193\n",
      "\n",
      "    accuracy                          0.833      1272\n",
      "   macro avg      0.609     0.542     0.546      1272\n",
      "weighted avg      0.784     0.833     0.798      1272\n",
      "\n",
      "F1-Score: 0.18461538461538463\n",
      "\n",
      "=== PERBANDINGAN LENGKAP ===\n",
      "F1-Score Baseline SVM  : 0.0\n",
      "F1-Score SVM + SMOTE   : 0.22837370242214533\n",
      "F1-Score SVM + SMOTE-IPF: 0.18461538461538463\n",
      "Improvement SMOTE-IPF vs SMOTE: -0.043758317806760705\n"
     ]
    }
   ],
   "source": [
    "# Test SMOTE-IPF yang sudah dioptimalkan\n",
    "print(\"=== TESTING SMOTE-IPF ===\")\n",
    "\n",
    "# Inisialisasi SMOTE-IPF dengan parameter optimal\n",
    "smote_ipf = SMOTE_IPF(\n",
    "    smote_k=5, \n",
    "    ipf_k=3, \n",
    "    max_iter=10, \n",
    "    sampling_strategy=0.5,\n",
    "    random_state=42, \n",
    "    verbose=True,\n",
    "    remove_only_synthetic=True\n",
    ")\n",
    "\n",
    "# Apply SMOTE-IPF\n",
    "X_ipf, y_ipf = smote_ipf.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nDistribusi akhir SMOTE-IPF: {np.bincount(y_ipf)}\")\n",
    "\n",
    "# Train SVM dengan data SMOTE-IPF\n",
    "svm_ipf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_ipf.fit(X_ipf, y_ipf)\n",
    "y_pred_ipf = svm_ipf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== HASIL SVM + SMOTE-IPF ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ipf, digits=3))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_ipf))\n",
    "\n",
    "# Perbandingan semua metode\n",
    "print(\"\\n=== PERBANDINGAN LENGKAP ===\")\n",
    "print(\"F1-Score Baseline SVM  :\", f1_score(y_test, y_pred_plain))\n",
    "print(\"F1-Score SVM + SMOTE   :\", f1_score(y_test, y_pred_smote))\n",
    "print(\"F1-Score SVM + SMOTE-IPF:\", f1_score(y_test, y_pred_ipf))\n",
    "print(\"Improvement SMOTE-IPF vs SMOTE:\", f1_score(y_test, y_pred_ipf) - f1_score(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EKSPERIMEN MENGURANGI BIAS ===\n",
      "[SMOTE] Total: 5034, Synthetic: 2066\n",
      "[SMOTE] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2517)}\n",
      "[IPF] Iter 1: Removed 74/498, Remaining: 4960, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2443)}\n",
      "[IPF] Iter 2: Removed 2/421, Remaining: 4958, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2441)}\n",
      "[IPF] Iter 3: Removed 1/420, Remaining: 4957, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2440)}\n",
      "[IPF] Iter 4: Only original misclassified -> STOP\n",
      "[FINAL] Total: 4957, Synthetic remaining: 1989\n",
      "[FINAL] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2440)}\n",
      "\n",
      "=== HASIL SVM + SMOTE-IPF + CLASS_WEIGHT ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.899     0.649     0.753      1079\n",
      "         1.0      0.231     0.591     0.332       193\n",
      "\n",
      "    accuracy                          0.640      1272\n",
      "   macro avg      0.565     0.620     0.543      1272\n",
      "weighted avg      0.797     0.640     0.690      1272\n",
      "\n",
      "F1-Score: 0.3323615160349854\n",
      "\n",
      "=== THRESHOLD TUNING ===\n",
      "Threshold 0.3: F1=0.336, Recall=0.580, Precision=0.236\n",
      "Threshold 0.4: F1=0.323, Recall=0.399, Precision=0.271\n",
      "Threshold 0.5: F1=0.313, Recall=0.295, Precision=0.333\n",
      "Threshold 0.6: F1=0.214, Recall=0.150, Precision=0.372\n",
      "Threshold 0.7: F1=0.107, Recall=0.062, Precision=0.387\n",
      "\n",
      "=== PERBANDINGAN BIAS (LENGKAP) ===\n",
      "Method                    | F1-Score | Recall-0 | Recall-1 | Bias\n",
      "--------------------------------------------------------------------\n",
      "Baseline SVM              | 0.000    | 1.000    | 0.000    | Ekstrem\n",
      "SVM + SMOTE               | 0.228    | 0.942    | 0.171    | Tinggi\n",
      "SVM + SMOTE-IPF           | 0.185    | 0.960    | 0.124    | Tinggi\n",
      "SVM + SMOTE-IPF + Balanced| 0.332    | 0.649    | 0.591    | Rendah\n",
      "\n",
      "=== ANALISIS BIAS REDUCTION ===\n",
      "Baseline: Recall gap = 1.000 (Ekstrem bias)\n",
      "SMOTE: Recall gap = 0.771 (Tinggi bias)\n",
      "SMOTE-IPF: Recall gap = 0.836 (Tinggi bias)\n",
      "Balanced: Recall gap = 0.058 (Rendah bias)\n",
      "\n",
      "ðŸŽ¯ KESIMPULAN:\n",
      "â€¢ Baseline: F1=0.000, Miss 100.0% kasus CHD\n",
      "â€¢ SMOTE: F1=0.228, Miss 82.9% kasus CHD\n",
      "â€¢ SMOTE-IPF: F1=0.185, Miss 87.6% kasus CHD\n",
      "â€¢ Balanced: F1=0.332, Miss 40.9% kasus CHD âœ…\n",
      "\n",
      "ðŸ“Š IMPROVEMENT:\n",
      "â€¢ SMOTE-IPF vs SMOTE: +-0.044 F1-score\n",
      "â€¢ Balanced vs SMOTE-IPF: +0.148 F1-score\n",
      "â€¢ Total improvement: +0.332 F1-score\n"
     ]
    }
   ],
   "source": [
    "print(\"=== EKSPERIMEN MENGURANGI BIAS ===\")\n",
    "\n",
    "# 1. Coba sampling_strategy lebih agresif (lebih balanced)\n",
    "smote_ipf_balanced = SMOTE_IPF(\n",
    "    smote_k=5, \n",
    "    ipf_k=3, \n",
    "    max_iter=10, \n",
    "    sampling_strategy=1.0,  # Lebih agresif\n",
    "    random_state=42, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_ipf_bal, y_ipf_bal = smote_ipf_balanced.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 2. SVM dengan class_weight balanced\n",
    "svm_balanced = SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=42)\n",
    "svm_balanced.fit(X_ipf_bal, y_ipf_bal)\n",
    "y_pred_balanced = svm_balanced.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== HASIL SVM + SMOTE-IPF + CLASS_WEIGHT ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_balanced, digits=3))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_balanced))\n",
    "\n",
    "# 3. Coba decision threshold tuning dengan probability\n",
    "svm_prob = SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "svm_prob.fit(X_ipf, y_ipf)\n",
    "y_prob = svm_prob.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Tuning threshold untuk balance precision-recall\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "print(\"\\n=== THRESHOLD TUNING ===\")\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    recall_1 = (y_pred_thresh[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "    precision_1 = (y_test[y_pred_thresh == 1] == 1).sum() / max(1, (y_pred_thresh == 1).sum())\n",
    "    print(f\"Threshold {thresh}: F1={f1:.3f}, Recall={recall_1:.3f}, Precision={precision_1:.3f}\")\n",
    "\n",
    "# Hitung semua recall terlebih dahulu\n",
    "recall_0_plain = (y_pred_plain[y_test == 0] == 0).sum() / (y_test == 0).sum() if (y_test == 0).sum() > 0 else 0\n",
    "recall_1_plain = (y_pred_plain[y_test == 1] == 1).sum() / (y_test == 1).sum() if (y_test == 1).sum() > 0 else 0\n",
    "\n",
    "recall_0_smote = (y_pred_smote[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_smote = (y_pred_smote[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "recall_0_ipf = (y_pred_ipf[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_ipf = (y_pred_ipf[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "recall_0_bal = (y_pred_balanced[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_bal = (y_pred_balanced[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "# Fungsi untuk menentukan status bias\n",
    "def get_bias_status(recall_0, recall_1):\n",
    "    if recall_1 == 0:\n",
    "        return \"Ekstrem\"\n",
    "    diff = abs(recall_0 - recall_1)\n",
    "    if diff > 0.3:\n",
    "        return \"Tinggi\"\n",
    "    elif diff > 0.1:\n",
    "        return \"Sedang\"\n",
    "    else:\n",
    "        return \"Rendah\"\n",
    "\n",
    "bias_plain = get_bias_status(recall_0_plain, recall_1_plain)\n",
    "bias_smote = get_bias_status(recall_0_smote, recall_1_smote)\n",
    "bias_ipf = get_bias_status(recall_0_ipf, recall_1_ipf)\n",
    "bias_bal = get_bias_status(recall_0_bal, recall_1_bal)\n",
    "\n",
    "# Perbandingan akhir LENGKAP\n",
    "print(\"\\n=== PERBANDINGAN BIAS (LENGKAP) ===\")\n",
    "print(\"Method                    | F1-Score | Recall-0 | Recall-1 | Bias\")\n",
    "print(\"-\" * 68)\n",
    "print(f\"Baseline SVM              | {f1_score(y_test, y_pred_plain):.3f}    | {recall_0_plain:.3f}    | {recall_1_plain:.3f}    | {bias_plain}\")\n",
    "print(f\"SVM + SMOTE               | {f1_score(y_test, y_pred_smote):.3f}    | {recall_0_smote:.3f}    | {recall_1_smote:.3f}    | {bias_smote}\")\n",
    "print(f\"SVM + SMOTE-IPF           | {f1_score(y_test, y_pred_ipf):.3f}    | {recall_0_ipf:.3f}    | {recall_1_ipf:.3f}    | {bias_ipf}\")\n",
    "print(f\"SVM + SMOTE-IPF + Balanced| {f1_score(y_test, y_pred_balanced):.3f}    | {recall_0_bal:.3f}    | {recall_1_bal:.3f}    | {bias_bal}\")\n",
    "\n",
    "# Analisis improvement bias\n",
    "print(f\"\\n=== ANALISIS BIAS REDUCTION ===\")\n",
    "print(f\"Baseline: Recall gap = {abs(recall_0_plain - recall_1_plain):.3f} ({bias_plain} bias)\")\n",
    "print(f\"SMOTE: Recall gap = {abs(recall_0_smote - recall_1_smote):.3f} ({bias_smote} bias)\")\n",
    "print(f\"SMOTE-IPF: Recall gap = {abs(recall_0_ipf - recall_1_ipf):.3f} ({bias_ipf} bias)\")\n",
    "print(f\"Balanced: Recall gap = {abs(recall_0_bal - recall_1_bal):.3f} ({bias_bal} bias)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KESIMPULAN:\")\n",
    "print(f\"â€¢ Baseline: F1={f1_score(y_test, y_pred_plain):.3f}, Miss {100*(1-recall_1_plain):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ SMOTE: F1={f1_score(y_test, y_pred_smote):.3f}, Miss {100*(1-recall_1_smote):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ SMOTE-IPF: F1={f1_score(y_test, y_pred_ipf):.3f}, Miss {100*(1-recall_1_ipf):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ Balanced: F1={f1_score(y_test, y_pred_balanced):.3f}, Miss {100*(1-recall_1_bal):.1f}% kasus CHD âœ…\")\n",
    "\n",
    "print(f\"\\nðŸ“Š IMPROVEMENT:\")\n",
    "print(f\"â€¢ SMOTE-IPF vs SMOTE: +{(f1_score(y_test, y_pred_ipf) - f1_score(y_test, y_pred_smote)):.3f} F1-score\")\n",
    "print(f\"â€¢ Balanced vs SMOTE-IPF: +{(f1_score(y_test, y_pred_balanced) - f1_score(y_test, y_pred_ipf)):.3f} F1-score\")\n",
    "print(f\"â€¢ Total improvement: +{(f1_score(y_test, y_pred_balanced) - f1_score(y_test, y_pred_plain)):.3f} F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EKSPERIMEN MENGURANGI BIAS ===\n",
      "[SMOTE] Total: 5034, Synthetic: 2066\n",
      "[SMOTE] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2517)}\n",
      "[IPF] Iter 1: Removed 74/498, Remaining: 4960, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2443)}\n",
      "[IPF] Iter 2: Removed 2/421, Remaining: 4958, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2441)}\n",
      "[IPF] Iter 3: Removed 1/420, Remaining: 4957, Distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2440)}\n",
      "[IPF] Iter 4: Only original misclassified -> STOP\n",
      "[FINAL] Total: 4957, Synthetic remaining: 1989\n",
      "[FINAL] Class distribution: {np.int64(0): np.int64(2517), np.int64(1): np.int64(2440)}\n",
      "\n",
      "=== HASIL SVM + SMOTE-IPF + CLASS_WEIGHT ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.899     0.649     0.753      1079\n",
      "         1.0      0.231     0.591     0.332       193\n",
      "\n",
      "    accuracy                          0.640      1272\n",
      "   macro avg      0.565     0.620     0.543      1272\n",
      "weighted avg      0.797     0.640     0.690      1272\n",
      "\n",
      "F1-Score: 0.3323615160349854\n",
      "\n",
      "=== THRESHOLD TUNING ===\n",
      "Threshold 0.3: F1=0.336, Recall=0.580, Precision=0.236\n",
      "Threshold 0.4: F1=0.323, Recall=0.399, Precision=0.271\n",
      "Threshold 0.5: F1=0.313, Recall=0.295, Precision=0.333\n",
      "Threshold 0.6: F1=0.214, Recall=0.150, Precision=0.372\n",
      "Threshold 0.7: F1=0.107, Recall=0.062, Precision=0.387\n",
      "\n",
      "=== PERBANDINGAN BIAS (LENGKAP) ===\n",
      "Method                    | F1-Score | Recall-0 | Recall-1 | Bias\n",
      "--------------------------------------------------------------------\n",
      "Baseline SVM              | 0.000    | 1.000    | 0.000    | Ekstrem\n",
      "SVM + SMOTE               | 0.228    | 0.942    | 0.171    | Tinggi\n",
      "SVM + SMOTE-IPF           | 0.185    | 0.960    | 0.124    | Tinggi\n",
      "SVM + SMOTE-IPF + Balanced| 0.332    | 0.649    | 0.591    | Rendah\n",
      "\n",
      "=== ANALISIS BIAS REDUCTION ===\n",
      "Baseline: Recall gap = 1.000 (Ekstrem bias)\n",
      "SMOTE: Recall gap = 0.771 (Tinggi bias)\n",
      "SMOTE-IPF: Recall gap = 0.836 (Tinggi bias)\n",
      "Balanced: Recall gap = 0.058 (Rendah bias)\n",
      "\n",
      "ðŸŽ¯ KESIMPULAN:\n",
      "â€¢ Baseline: F1=0.000, Miss 100.0% kasus CHD\n",
      "â€¢ SMOTE: F1=0.228, Miss 82.9% kasus CHD\n",
      "â€¢ SMOTE-IPF: F1=0.185, Miss 87.6% kasus CHD\n",
      "â€¢ Balanced: F1=0.332, Miss 40.9% kasus CHD âœ…\n",
      "\n",
      "ðŸ“Š IMPROVEMENT:\n",
      "â€¢ SMOTE-IPF vs SMOTE: +-0.044 F1-score\n",
      "â€¢ Balanced vs SMOTE-IPF: +0.148 F1-score\n",
      "â€¢ Total improvement: +0.332 F1-score\n"
     ]
    }
   ],
   "source": [
    "print(\"=== EKSPERIMEN MENGURANGI BIAS ===\")\n",
    "\n",
    "# 1. Coba sampling_strategy lebih agresif (lebih balanced)\n",
    "smote_ipf_balanced = SMOTE_IPF(\n",
    "    smote_k=5, \n",
    "    ipf_k=3, \n",
    "    max_iter=10, \n",
    "    sampling_strategy=1.0,  # Best 0.8\n",
    "    random_state=42, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_ipf_bal, y_ipf_bal = smote_ipf_balanced.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 2. SVM dengan class_weight balanced\n",
    "svm_balanced = SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=42)\n",
    "svm_balanced.fit(X_ipf_bal, y_ipf_bal)\n",
    "y_pred_balanced = svm_balanced.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== HASIL SVM + SMOTE-IPF + CLASS_WEIGHT ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_balanced, digits=3))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_balanced))\n",
    "\n",
    "# 3. Coba decision threshold tuning dengan probability\n",
    "svm_prob = SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "svm_prob.fit(X_ipf, y_ipf)\n",
    "y_prob = svm_prob.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Tuning threshold untuk balance precision-recall\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "print(\"\\n=== THRESHOLD TUNING ===\")\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    recall_1 = (y_pred_thresh[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "    precision_1 = (y_test[y_pred_thresh == 1] == 1).sum() / max(1, (y_pred_thresh == 1).sum())\n",
    "    print(f\"Threshold {thresh}: F1={f1:.3f}, Recall={recall_1:.3f}, Precision={precision_1:.3f}\")\n",
    "\n",
    "# Hitung semua recall terlebih dahulu\n",
    "recall_0_plain = (y_pred_plain[y_test == 0] == 0).sum() / (y_test == 0).sum() if (y_test == 0).sum() > 0 else 0\n",
    "recall_1_plain = (y_pred_plain[y_test == 1] == 1).sum() / (y_test == 1).sum() if (y_test == 1).sum() > 0 else 0\n",
    "\n",
    "recall_0_smote = (y_pred_smote[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_smote = (y_pred_smote[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "recall_0_ipf = (y_pred_ipf[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_ipf = (y_pred_ipf[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "recall_0_bal = (y_pred_balanced[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "recall_1_bal = (y_pred_balanced[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "\n",
    "# Fungsi untuk menentukan status bias\n",
    "def get_bias_status(recall_0, recall_1):\n",
    "    if recall_1 == 0:\n",
    "        return \"Ekstrem\"\n",
    "    diff = abs(recall_0 - recall_1)\n",
    "    if diff > 0.3:\n",
    "        return \"Tinggi\"\n",
    "    elif diff > 0.1:\n",
    "        return \"Sedang\"\n",
    "    else:\n",
    "        return \"Rendah\"\n",
    "\n",
    "bias_plain = get_bias_status(recall_0_plain, recall_1_plain)\n",
    "bias_smote = get_bias_status(recall_0_smote, recall_1_smote)\n",
    "bias_ipf = get_bias_status(recall_0_ipf, recall_1_ipf)\n",
    "bias_bal = get_bias_status(recall_0_bal, recall_1_bal)\n",
    "\n",
    "# Perbandingan akhir LENGKAP\n",
    "print(\"\\n=== PERBANDINGAN BIAS (LENGKAP) ===\")\n",
    "print(\"Method                    | F1-Score | Recall-0 | Recall-1 | Bias\")\n",
    "print(\"-\" * 68)\n",
    "print(f\"Baseline SVM              | {f1_score(y_test, y_pred_plain):.3f}    | {recall_0_plain:.3f}    | {recall_1_plain:.3f}    | {bias_plain}\")\n",
    "print(f\"SVM + SMOTE               | {f1_score(y_test, y_pred_smote):.3f}    | {recall_0_smote:.3f}    | {recall_1_smote:.3f}    | {bias_smote}\")\n",
    "print(f\"SVM + SMOTE-IPF           | {f1_score(y_test, y_pred_ipf):.3f}    | {recall_0_ipf:.3f}    | {recall_1_ipf:.3f}    | {bias_ipf}\")\n",
    "print(f\"SVM + SMOTE-IPF + Balanced| {f1_score(y_test, y_pred_balanced):.3f}    | {recall_0_bal:.3f}    | {recall_1_bal:.3f}    | {bias_bal}\")\n",
    "\n",
    "# Analisis improvement bias\n",
    "print(f\"\\n=== ANALISIS BIAS REDUCTION ===\")\n",
    "print(f\"Baseline: Recall gap = {abs(recall_0_plain - recall_1_plain):.3f} ({bias_plain} bias)\")\n",
    "print(f\"SMOTE: Recall gap = {abs(recall_0_smote - recall_1_smote):.3f} ({bias_smote} bias)\")\n",
    "print(f\"SMOTE-IPF: Recall gap = {abs(recall_0_ipf - recall_1_ipf):.3f} ({bias_ipf} bias)\")\n",
    "print(f\"Balanced: Recall gap = {abs(recall_0_bal - recall_1_bal):.3f} ({bias_bal} bias)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KESIMPULAN:\")\n",
    "print(f\"â€¢ Baseline: F1={f1_score(y_test, y_pred_plain):.3f}, Miss {100*(1-recall_1_plain):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ SMOTE: F1={f1_score(y_test, y_pred_smote):.3f}, Miss {100*(1-recall_1_smote):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ SMOTE-IPF: F1={f1_score(y_test, y_pred_ipf):.3f}, Miss {100*(1-recall_1_ipf):.1f}% kasus CHD\")\n",
    "print(f\"â€¢ Balanced: F1={f1_score(y_test, y_pred_balanced):.3f}, Miss {100*(1-recall_1_bal):.1f}% kasus CHD âœ…\")\n",
    "\n",
    "print(f\"\\nðŸ“Š IMPROVEMENT:\")\n",
    "print(f\"â€¢ SMOTE-IPF vs SMOTE: +{(f1_score(y_test, y_pred_ipf) - f1_score(y_test, y_pred_smote)):.3f} F1-score\")\n",
    "print(f\"â€¢ Balanced vs SMOTE-IPF: +{(f1_score(y_test, y_pred_balanced) - f1_score(y_test, y_pred_ipf)):.3f} F1-score\")\n",
    "print(f\"â€¢ Total improvement: +{(f1_score(y_test, y_pred_balanced) - f1_score(y_test, y_pred_plain)):.3f} F1-score\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGsyVEIzDJLM9tH5/fZbRf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
